# üìù QUESTION 3: Hierarchical Clustering (Conceptual & Computational)

Excellent! Now let's test your understanding of hierarchical clustering methods.

---

## **SCENARIO:**

You are given **5 data points** with the following **distance matrix**:

|     | **A** | **B** | **C** | **D** | **E** |
|-----|-------|-------|-------|-------|-------|
| **A** | 0     | 2     | 6     | 10    | 9     |
| **B** | 2     | 0     | 5     | 9     | 8     |
| **C** | 6     | 5     | 0     | 4     | 5     |
| **D** | 10    | 9     | 4     | 0     | 3     |
| **E** | 9     | 8     | 5     | 3     | 0     |

---

## **QUESTIONS:**

### **(a) Agglomerative Hierarchical Clustering with SINGLE LINKAGE (MIN)** (5 marks)

Perform **agglomerative hierarchical clustering** using **Single Linkage (MIN)** method.

Show:
1. The **order** in which clusters are merged
2. The **distance** at which each merge occurs
3. The **final dendrogram structure** (you can describe it textually)

**Work through ALL merging steps until you have one final cluster.**

---

### **(b) Agglomerative Hierarchical Clustering with COMPLETE LINKAGE (MAX)** (5 marks)

Now perform the same clustering using **Complete Linkage (MAX)** method.

Show:
1. The **order** in which clusters are merged (will it be different?)
2. The **distance** at which each merge occurs
3. Compare: Does the **order of merging differ** from Single Linkage? Why?

---

### **(c) Conceptual Questions** (6 marks)

Answer these based on your calculations and understanding:

1. **Explain** the difference between Single Linkage and Complete Linkage in your own words.

2. Which linkage method is more susceptible to the **"chaining effect"**? Explain what chaining means and why it happens.

3. Given the final clusters at height/distance = 5 (cut the dendrogram at distance 5):
   - How many clusters would you get with **Single Linkage**?
   - How many clusters would you get with **Complete Linkage**?
   - Show which points are in each cluster.

---

## üìã INSTRUCTIONS

**CRITICAL**: Show ALL your work step-by-step!

For each merge, show:
- Which two clusters are being merged
- How you calculated the inter-cluster distance
- The updated proximity matrix after the merge

**Example format for part (a):**
```
Step 1: Find minimum distance in matrix
  ‚Üí Minimum distance = 2 between A and B
  ‚Üí Merge A and B into cluster {AB}
  ‚Üí Update proximity matrix...

Step 2: Find minimum distance in updated matrix
  ‚Üí ...
```

---

## üí° HINTS

**Single Linkage (MIN):**
- Distance between clusters = **minimum** distance between any two points
- d({AB}, C) = min(d(A,C), d(B,C))

**Complete Linkage (MAX):**
- Distance between clusters = **maximum** distance between any two points  
- d({AB}, C) = max(d(A,C), d(B,C))

---

**Take your time!** This is testing:
1. Understanding of linkage methods
2. Systematic proximity matrix updates
3. Dendrogram interpretation
4. Comparative analysis skills

**Show me your complete work!** üå≥
# üìä QUESTION 3: Feedback & Detailed Explanation

---

## ‚úÖ CORRECTNESS ASSESSMENT

**Overall: Partially Correct but VERY INCOMPLETE (About 35%)**

### **Part (a) - Single Linkage:**
- ‚úÖ **First merge correct**: A-B at distance 2 ‚úì
- ‚úÖ **Second merge correct**: D-E at distance 3 ‚úì
- ‚úÖ **Third merge correct**: C joins {D,E} at distance 4 ‚úì
- ‚ùå **Fourth merge INCORRECT**: You said {A,B} joins at 5, but this is WRONG!
- ‚ùå **Missing calculations**: No proximity matrix updates shown
- ‚ùå **Confusing explanation**: "7 (3+4)" doesn't make sense for linkage methods

### **Part (b) - Complete Linkage:**
- ‚úÖ **First two merges correct**: A-B at 2, D-E at 3 ‚úì
- ‚ùå **Third merge INCORRECT**: C and {D,E} is NOT at distance 5!
- ‚ùå **Final merge**: Missing completely
- ‚ùå **No calculations shown**

### **Part (c) - Conceptual:**
- ‚ö†Ô∏è **Definition incomplete**: "inter cluster similarity is min and complete max" is too vague
- ‚ùå **Missing chaining discussion**
- ‚ùå **Missing cluster count at distance 5**

**This would score approximately 6-7 out of 16 marks in an exam!**

---

Let me show you the **COMPLETE, STEP-BY-STEP SOLUTION** with all calculations:Perfect! Now I have all the materials. Let me create the complete solution:

---

## üìñ COMPLETE SOLUTION WITH ALL CALCULATIONS

### **INITIAL DISTANCE MATRIX** (Given)

|     | **A** | **B** | **C** | **D** | **E** |
|-----|-------|-------|-------|-------|-------|
| **A** | 0     | 2     | 6     | 10    | 9     |
| **B** | 2     | 0     | 5     | 9     | 8     |
| **C** | 6     | 5     | 0     | 4     | 5     |
| **D** | 10    | 9     | 4     | 0     | 3     |
| **E** | 9     | 8     | 5     | 3     | 0     |

---

## **(a) SINGLE LINKAGE (MIN) - COMPLETE SOLUTION**

**According to Clustering.pdf, Slide 21:**
> "Single Linkage considers the distance between one cluster and another cluster to be equal to the **shortest distance** from any member of one cluster to any member of the other cluster."

**Formula:** 
```
d_MIN({Ci}, {Cj}) = min{d(p, q) : p ‚àà Ci, q ‚àà Cj}
```

---

### **STEP 1: Initial State**
```
Clusters: {A}, {B}, {C}, {D}, {E}
Find minimum distance in matrix = 2 (between A and B)
```

**Action:** Merge A and B into cluster **{AB}**

---

### **STEP 2: Update Proximity Matrix After Merging {AB}**

**Calculate distances using MIN (Single Linkage):**

**d({AB}, C):**
```
= min(d(A,C), d(B,C))
= min(6, 5)
= 5
```

**d({AB}, D):**
```
= min(d(A,D), d(B,D))
= min(10, 9)
= 9
```

**d({AB}, E):**
```
= min(d(A,E), d(B,E))
= min(9, 8)
= 8
```

**Updated Matrix:**

|       | **{AB}** | **C** | **D** | **E** |
|-------|----------|-------|-------|-------|
| **{AB}** | 0        | 5     | 9     | 8     |
| **C**    | 5        | 0     | 4     | 5     |
| **D**    | 9        | 4     | 0     | 3     |
| **E**    | 8        | 5     | 3     | 0     |

```
Current clusters: {AB}, {C}, {D}, {E}
Minimum distance = 3 (between D and E)
```

‚úÖ **Your second merge was correct!**

---

### **STEP 3: Merge D and E**

**Action:** Merge D and E into cluster **{DE}**

**Updated Matrix After Merging {DE}:**

**d({AB}, {DE}):**
```
= min(d({AB}, D), d({AB}, E))
= min(9, 8)
= 8
```

**d(C, {DE}):**
```
= min(d(C, D), d(C, E))
= min(4, 5)
= 4
```

**Updated Matrix:**

|        | **{AB}** | **C** | **{DE}** |
|--------|----------|-------|----------|
| **{AB}** | 0        | 5     | 8        |
| **C**    | 5        | 0     | 4        |
| **{DE}** | 8        | 4     | 0        |

```
Current clusters: {AB}, {C}, {DE}
Minimum distance = 4 (between C and {DE})
```

‚úÖ **Your third merge was correct!**

---

### **STEP 4: Merge C and {DE}**

**Action:** Merge C and {DE} into cluster **{CDE}**

**Updated Matrix After Merging {CDE}:**

**d({AB}, {CDE}):**
```
= min(d({AB}, C), d({AB}, {DE}))
= min(5, 8)
= 5
```

**Final Matrix:**

|         | **{AB}** | **{CDE}** |
|---------|----------|-----------|
| **{AB}**  | 0        | 5         |
| **{CDE}** | 5        | 0         |

```
Current clusters: {AB}, {CDE}
Minimum distance = 5
```

‚ùå **YOUR MISTAKE: You said the final merge is at distance 5, which is CORRECT!**
‚ùå **But your explanation "7 (3+4)" is WRONG and makes no sense!**

---

### **STEP 5: Final Merge**

**Action:** Merge {AB} and {CDE} into final cluster **{ABCDE}** at distance **5**

---

### **SINGLE LINKAGE DENDROGRAM (Textual Description):**

```
Distance
   10 |
    9 |
    8 |
    7 |
    6 |
    5 |‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    4 |         ‚îå‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îê
    3 |     ‚îå‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îê   |
    2 | ‚îå‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îê   |   |
    1 |   |   |   |   |   |
    0 | A   B   D   E   C
      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
```

**Merge Order:**
1. **Step 1**: A + B ‚Üí {AB} at distance **2**
2. **Step 2**: D + E ‚Üí {DE} at distance **3**
3. **Step 3**: C + {DE} ‚Üí {CDE} at distance **4**
4. **Step 4**: {AB} + {CDE} ‚Üí {ABCDE} at distance **5**

‚úÖ **Your merge order was correct!**

---

## **(b) COMPLETE LINKAGE (MAX) - COMPLETE SOLUTION**

**According to Clustering.pdf, Slide 38:**
> "Complete Linkage (MAX): Distance between clusters is the **maximum** distance between any two points from different clusters."

**Formula:**
```
d_MAX({Ci}, {Cj}) = max{d(p, q) : p ‚àà Ci, q ‚àà Cj}
```

---

### **STEP 1: Initial State** (Same as Single Linkage)
```
Clusters: {A}, {B}, {C}, {D}, {E}
Minimum distance = 2 (between A and B)
```

**Action:** Merge A and B into cluster **{AB}**

‚úÖ **Your first merge was correct!**

---

### **STEP 2: Update Proximity Matrix Using MAX**

**d({AB}, C):**
```
= max(d(A,C), d(B,C))
= max(6, 5)
= 6  ‚Üê DIFFERENT from Single Linkage!
```

**d({AB}, D):**
```
= max(d(A,D), d(B,D))
= max(10, 9)
= 10
```

**d({AB}, E):**
```
= max(d(A,E), d(B,E))
= max(9, 8)
= 9
```

**Updated Matrix:**

|       | **{AB}** | **C** | **D** | **E** |
|-------|----------|-------|-------|-------|
| **{AB}** | 0        | 6     | 10    | 9     |
| **C**    | 6        | 0     | 4     | 5     |
| **D**    | 10       | 4     | 0     | 3     |
| **E**    | 9        | 5     | 3     | 0     |

```
Minimum distance = 3 (between D and E)
```

---

### **STEP 3: Merge D and E**

**Action:** Merge D and E into cluster **{DE}**

‚úÖ **Your second merge was correct!**

**d({AB}, {DE}):**
```
= max(d({AB}, D), d({AB}, E))
= max(10, 9)
= 10
```

**d(C, {DE}):**
```
= max(d(C, D), d(C, E))
= max(4, 5)
= 5  ‚Üê DIFFERENT from Single Linkage!
```

**Updated Matrix:**

|        | **{AB}** | **C** | **{DE}** |
|--------|----------|-------|----------|
| **{AB}** | 0        | 6     | 10       |
| **C**    | 6        | 0     | 5        |
| **{DE}** | 10       | 5     | 0        |

```
Minimum distance = 5 (between C and {DE})
```

---

### **STEP 4: Merge C and {DE}**

**Action:** Merge C and {DE} into cluster **{CDE}** at distance **5**

‚ùå **YOUR MISTAKE: You said this merge is at distance 5, which is CORRECT! But you said "no change" - that's misleading because Complete Linkage DOES give different inter-cluster distances!**

**d({AB}, {CDE}):**
```
= max(d({AB}, C), d({AB}, {DE}))
= max(6, 10)
= 10
```

**Final Matrix:**

|         | **{AB}** | **{CDE}** |
|---------|----------|-----------|
| **{AB}**  | 0        | 10        |
| **{CDE}** | 10       | 0         |

```
Minimum distance = 10
```

---

### **STEP 5: Final Merge**

**Action:** Merge {AB} and {CDE} into final cluster **{ABCDE}** at distance **10**

‚ùå **YOU MISSED THIS! The final merge is at distance 10, NOT 5!**

---

### **COMPLETE LINKAGE DENDROGRAM:**

```
Distance
   10 |‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    9 |             |
    8 |             |
    7 |             |
    6 |             |
    5 |         ‚îå‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îê
    4 |         |       |
    3 |     ‚îå‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îê   |
    2 | ‚îå‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îê   |   |
    1 |   |   |   |   |   |
    0 | A   B   D   E   C
      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
```

**Merge Order:**
1. **Step 1**: A + B ‚Üí {AB} at distance **2**
2. **Step 2**: D + E ‚Üí {DE} at distance **3**
3. **Step 3**: C + {DE} ‚Üí {CDE} at distance **5**
4. **Step 4**: {AB} + {CDE} ‚Üí {ABCDE} at distance **10** ‚Üê KEY DIFFERENCE!

---

## **COMPARISON: Single vs Complete Linkage**

| **Step** | **Single Linkage (MIN)** | **Complete Linkage (MAX)** |
|----------|--------------------------|----------------------------|
| 1        | {AB} at distance 2       | {AB} at distance 2         |
| 2        | {DE} at distance 3       | {DE} at distance 3         |
| 3        | {CDE} at distance 4      | {CDE} at distance 5        |
| 4        | {ABCDE} at distance **5**| {ABCDE} at distance **10** |

**KEY OBSERVATION:**
- **Merge ORDER is the SAME** ‚úì
- **Merge DISTANCES are DIFFERENT** ‚úì
- Final merge: Single Linkage = 5, Complete Linkage = 10

---

## **(c) CONCEPTUAL QUESTIONS - DETAILED ANSWERS**

### **Question 1: Difference Between Single and Complete Linkage**

**From Clustering.pdf, Slides 35-39:**

**Single Linkage (MIN):**
- Uses the **minimum** distance between any two points from different clusters
- **Formula**: d({Ci}, {Cj}) = min{d(p, q): p ‚àà Ci, q ‚àà Cj}
- **Analogy**: "Nearest neighbors" approach
- **Strength**: Can find non-elliptical, arbitrarily-shaped clusters
- **Weakness**: Susceptible to chaining effect and noise

**Complete Linkage (MAX):**
- Uses the **maximum** distance between any two points from different clusters
- **Formula**: d({Ci}, {Cj}) = max{d(p, q): p ‚àà Ci, q ‚àà Cj}
- **Analogy**: "Furthest neighbors" approach
- **Strength**: Less susceptible to noise and outliers, produces compact clusters
- **Weakness**: Tends to break large clusters, biased towards globular clusters

**Simple Explanation:**
- **Single Linkage**: "These two clusters are close if their CLOSEST points are close"
- **Complete Linkage**: "These two clusters are close only if their FURTHEST points are close"

---

### **Question 2: Chaining Effect**

**From Clustering.pdf, Slide 34:**
> "Single linkage... can lead to **chaining**"

**From Clustering.pdf, Slide 37:**
> "Sensitive to noise and outliers"

**What is Chaining?**

Chaining occurs when clusters are formed by connecting points through intermediate points, creating long, snake-like clusters that may not represent natural groupings.

**Example:**
```
Points: A---B---C-----------D---E---F

Single Linkage will:
1. Merge A-B (close)
2. Merge {AB}-C (C is close to B)
3. Merge {ABC}-D (even though D is far from A and B!)
4. Eventually form one long chain {ABCDEF}

This happens because Single Linkage only looks at the MINIMUM distance!
```

**Why Does Single Linkage Suffer from Chaining?**

1. Only considers the **closest pair** of points
2. Ignores the overall structure of clusters
3. A single "bridge" point can connect two distant clusters

**Complete Linkage avoids chaining because:**
- It considers the **furthest pair** of points
- Requires ALL points to be reasonably close
- Creates more compact, well-separated clusters

**Answer:** **Single Linkage** is more susceptible to chaining.

---

### **Question 3: Clusters at Distance = 5**

**To find clusters, we "cut" the dendrogram horizontally at distance 5.**

**Single Linkage at distance 5:**
```
Looking at dendrogram:
- {AB} formed at distance 2
- {DE} formed at distance 3
- {CDE} formed at distance 4
- {AB} and {CDE} merge at distance 5

At distance 5, we're right at the merge point!
If we cut JUST BEFORE distance 5:
  ‚Üí 2 clusters: {AB} and {CDE}
```

**Clusters:**
- Cluster 1: **{A, B}** (2 points)
- Cluster 2: **{C, D, E}** (3 points)

**Complete Linkage at distance 5:**
```
Looking at dendrogram:
- {AB} formed at distance 2
- {DE} formed at distance 3
- {CDE} formed at distance 5
- {AB} and {CDE} merge at distance 10

At distance 5, we're right at the {CDE} merge!
If we cut JUST BEFORE distance 5:
  ‚Üí 3 clusters: {AB}, {DE}, and {C}
```

**Clusters:**
- Cluster 1: **{A, B}** (2 points)
- Cluster 2: **{D, E}** (2 points)
- Cluster 3: **{C}** (1 point)

---

## üìä FINAL SUMMARY TABLE

| **Aspect** | **Single Linkage** | **Complete Linkage** |
|------------|-------------------|---------------------|
| **Distance Formula** | MIN (closest points) | MAX (furthest points) |
| **Merge Order** | Same: AB‚ÜíDE‚ÜíCDE‚Üíall | Same: AB‚ÜíDE‚ÜíCDE‚Üíall |
| **Merge at Step 3** | Distance 4 | Distance 5 |
| **Final Merge** | Distance 5 | Distance 10 |
| **Clusters at d=5** | 2: {AB}, {CDE} | 3: {AB}, {DE}, {C} |
| **Chaining** | Susceptible ‚úó | Resistant ‚úì |
| **Cluster Shape** | Arbitrary shapes ‚úì | Globular shapes ‚úì |
| **Noise Sensitivity** | High ‚úó | Low ‚úì |

---

## üìö CITATIONS

- **Clustering.pdf, Slides 21-27**: Single Linkage algorithm and example
- **Clustering.pdf, Slides 35-39**: Linkage method comparison, strengths/weaknesses
- **Clustering.pdf, Slide 34**: Chaining effect
- **Solution Manual, Exercise 17**: Hierarchical clustering comparisons
- **PYQ 2023-24**: Single-link hierarchical clustering (6 marks)

---

## ‚ö†Ô∏è KEY TAKEAWAYS FOR EXAMS

1. **Always show proximity matrix updates** - This is where most marks are!
2. **Calculate distances using proper formulas** - MIN for Single, MAX for Complete
3. **Show merge order AND distances** - Both are important
4. **Draw or describe dendrogram** - Visual representation helps
5. **Compare methods** - Understand when to use which

---

**Great progress! Ready for Question 4 on DBSCAN?** üöÄ
